{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "883f3fd6",
   "metadata": {},
   "source": [
    "Last things I did:\n",
    "\n",
    "- Implement SMOTE\n",
    "- Use SMOTE on SVM\n",
    "- Try to build a Neural Network with Tensorflow. Watch this: https://youtu.be/VtRLrQ3Ev-U?si=RIMFdXbsnMavwTxH&t=3093"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ee048d6",
   "metadata": {},
   "source": [
    "## Importing Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d66ef4be",
   "metadata": {},
   "outputs": [],
   "source": [
    "# IMPORTING LIBRARIES\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from imblearn.over_sampling import SMOTE\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.tree import plot_tree\n",
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c912575",
   "metadata": {},
   "source": [
    "## NHanes data from 2017 - 2020"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0ccc26d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('/Users/tobiasmadsen/Documents/UMich/MDST/NHANES/data_files/eda_data.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1bd5215",
   "metadata": {},
   "source": [
    "## Prep"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a1f3e66",
   "metadata": {},
   "source": [
    "### Train Test Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19d3aa59",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the data into X (features) and y (target)\n",
    "X = df_merged.drop('Doctor_Told_Diabetes', axis=1)\n",
    "y = df_merged['Doctor_Told_Diabetes']\n",
    "\n",
    "# Split data into training and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ec896c8",
   "metadata": {},
   "source": [
    "### Scaling the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7244d036",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scaling the data\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8256c865",
   "metadata": {},
   "source": [
    "### SMOTE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "972c5bb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply SMOTE\n",
    "smote = SMOTE(random_state=42)\n",
    "X_train_smote, y_train_smote = smote.fit_resample(X_train_scaled, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5ae8851",
   "metadata": {},
   "source": [
    "## Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9c315b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize logistic regression model\n",
    "logreg = LogisticRegression(max_iter=10000)\n",
    "\n",
    "# Fit the model to the training data\n",
    "logreg.fit(X_train_smote, y_train_smote)\n",
    "\n",
    "# Predict on test data\n",
    "y_pred = logreg.predict(X_test_scaled)\n",
    "\n",
    "# Evaluate the model\n",
    "print(\"Accuracy:\", accuracy_score(y_test, y_pred))\n",
    "print(classification_report(y_test, y_pred))\n",
    "\n",
    "coefficients = logreg.coef_[0]\n",
    "features = X.columns\n",
    "\n",
    "coeff_df = pd.DataFrame({'Feature': features, 'Coefficient': coefficients})\n",
    "\n",
    "sorted_coeff_df = coeff_df.sort_values(by='Coefficient', ascending=False)\n",
    "\n",
    "\n",
    "print(sorted_coeff_df)\n",
    "\n",
    "# Generate the confusion matrix\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "\n",
    "# Display the confusion matrix\n",
    "print(\"Confusion Matrix:\")\n",
    "print(cm)\n",
    "\n",
    "# Optionally, visualize the confusion matrix using seaborn\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.heatmap(cm, annot=True, fmt='g', cmap='Reds', \n",
    "            xticklabels=['Predicted 0', 'Predicted 1'], \n",
    "            yticklabels=['Actual 0', 'Actual 1'])\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43a792b4",
   "metadata": {},
   "source": [
    "## Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56d89261",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize decision tree model\n",
    "dtree = DecisionTreeClassifier(random_state=42)\n",
    "\n",
    "# Fit the model to the training data\n",
    "dtree.fit(X_train, y_train)\n",
    "\n",
    "# Predict on test data using decision tree\n",
    "y_pred_tree = dtree.predict(X_test)\n",
    "\n",
    "# Calculate and print the accuracy\n",
    "accuracy = accuracy_score(y_test, y_pred_tree)\n",
    "print(f\"Decision Tree Accuracy: {accuracy:.4f}\")\n",
    "\n",
    "# Print a detailed classification report\n",
    "print(classification_report(y_test, y_pred_tree))\n",
    "\n",
    "\n",
    "# plt.figure(figsize=(30,15))\n",
    "# plot_tree(dtree, filled=True, feature_names=list(X.columns), class_names=['No Diabetes', 'Diabetes'], max_depth=3)\n",
    "# plt.show()\n",
    "\n",
    "# Compute the confusion matrix\n",
    "cm = confusion_matrix(y_test, y_pred_tree)\n",
    "\n",
    "# Visualize the confusion matrix using Seaborn\n",
    "plt.figure(figsize=(8,6))\n",
    "sns.heatmap(cm, annot=True, fmt='g', cmap='Reds', \n",
    "            xticklabels=['Predicted Negative', 'Predicted Positive'], \n",
    "            yticklabels=['Actual Negative', 'Actual Positive'])\n",
    "plt.title('Decision Tree Confusion Matrix')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "781ccb11",
   "metadata": {},
   "source": [
    "## Random Forrest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8a71ec7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize random forest model\n",
    "rf = RandomForestClassifier(random_state=42, n_estimators=100)  # using 100 trees\n",
    "\n",
    "# Fit the model to the training data\n",
    "rf.fit(X_train_smote, y_train_smote)\n",
    "\n",
    "# Predict on test data using random forest\n",
    "y_pred_rf = rf.predict(X_test_scaled)\n",
    "\n",
    "# Calculate and print the accuracy\n",
    "accuracy = accuracy_score(y_test, y_pred_rf)\n",
    "print(f\"Random Forest Accuracy: {accuracy:.4f}\")\n",
    "\n",
    "# Print a detailed classification report\n",
    "print(classification_report(y_test, y_pred_rf))\n",
    "\n",
    "# Compute confusion matrix\n",
    "cm = confusion_matrix(y_test, y_pred_rf)\n",
    "\n",
    "# Plot using Seaborn\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.heatmap(cm, annot=True, fmt='g', cmap='Blues', \n",
    "            xticklabels=['Predicted 0', 'Predicted 1'], \n",
    "            yticklabels=['Actual 0', 'Actual 1'])\n",
    "\n",
    "plt.title('Confusion Matrix for Random Forest Classifier')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05f47df1",
   "metadata": {},
   "source": [
    "## KNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "482da0ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "# Initialize the KNN model\n",
    "knn = KNeighborsClassifier(n_neighbors=5)\n",
    "\n",
    "# Fit the model to the training data\n",
    "knn.fit(X_train_smote, y_train_smote)\n",
    "\n",
    "# Predict on test data\n",
    "y_pred_knn = knn.predict(X_test_scaled)\n",
    "\n",
    "# Evaluate the model\n",
    "print(\"KNN Model Accuracy:\", accuracy_score(y_test, y_pred_knn))\n",
    "print(classification_report(y_test, y_pred_knn))\n",
    "\n",
    "# Generate and display the confusion matrix for KNN model\n",
    "cm_knn = confusion_matrix(y_test, y_pred_knn)\n",
    "print(\"KNN Model Confusion Matrix:\")\n",
    "print(cm_knn)\n",
    "\n",
    "# Optionally, visualize the confusion matrix of the KNN model\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.heatmap(cm_knn, annot=True, fmt='g', cmap='Greens', \n",
    "            xticklabels=['Predicted 0', 'Predicted 1'], \n",
    "            yticklabels=['Actual 0', 'Actual 1'])\n",
    "plt.title(\"Confusion Matrix for KNN Model\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2bfe101",
   "metadata": {},
   "source": [
    "### GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "060a49ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# Define the parameter grid: number of neighbors\n",
    "param_grid = {\n",
    "    'n_neighbors': [3, 5, 7, 9, 11, 13, 15],\n",
    "    'weights': ['uniform', 'distance'],\n",
    "    'metric': ['euclidean', 'manhattan', 'minkowski']\n",
    "}\n",
    "\n",
    "# Initialize a KNN classifier\n",
    "knn = KNeighborsClassifier()\n",
    "\n",
    "# Initialize GridSearchCV\n",
    "grid_search = GridSearchCV(estimator=knn, param_grid=param_grid, \n",
    "                           cv=5, n_jobs=-1, verbose=2, scoring='accuracy')\n",
    "\n",
    "# Fit GridSearchCV to the training data\n",
    "grid_search.fit(X_train_scaled, y_train)\n",
    "\n",
    "# Print the best parameters and the best score\n",
    "print(\"Best Parameters:\", grid_search.best_params_)\n",
    "print(\"Best Score:\", grid_search.best_score_)\n",
    "\n",
    "# Predict using the best model\n",
    "best_knn = grid_search.best_estimator_\n",
    "y_pred_best_knn = best_knn.predict(X_test_scaled)\n",
    "\n",
    "# Evaluate the best model\n",
    "print(\"Accuracy of Best KNN Model:\", accuracy_score(y_test, y_pred_best_knn))\n",
    "print(classification_report(y_test, y_pred_best_knn))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bbf152b6",
   "metadata": {},
   "source": [
    "## SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81cafca7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC\n",
    "\n",
    "# Initialize the SVM model\n",
    "svm_model = SVC(kernel=\"rbf\", class_weight=\"balanced\") \n",
    "\n",
    "# Fit the model to the training data\n",
    "svm_model.fit(X_train_smote, y_train_smote)\n",
    "\n",
    "# Predict on test data\n",
    "y_pred_svm = svm_model.predict(X_test_scaled)\n",
    "\n",
    "# Evaluate the model\n",
    "print(\"SVM Model Accuracy:\", accuracy_score(y_test, y_pred_svm))\n",
    "print(classification_report(y_test, y_pred_svm))\n",
    "\n",
    "# Generate and display the confusion matrix for SVM model\n",
    "cm_svm = confusion_matrix(y_test, y_pred_svm)\n",
    "print(\"SVM Model Confusion Matrix:\")\n",
    "print(cm_svm)\n",
    "\n",
    "# Optionally, visualize the confusion matrix of the SVM model\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.heatmap(cm_svm, annot=True, fmt='g', cmap='Blues', \n",
    "            xticklabels=['Predicted 0', 'Predicted 1'], \n",
    "            yticklabels=['Actual 0', 'Actual 1'])\n",
    "plt.title(\"Confusion Matrix for SVM Model\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3201cbe",
   "metadata": {},
   "source": [
    "## Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b913faf6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout\n",
    "from keras.optimizers import Adam\n",
    "from keras.callbacks import EarlyStopping\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e13db885",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "model = Sequential()\n",
    "\n",
    "# Input layer\n",
    "model.add(Dense(64, activation='relu', input_shape=(X_train_smote.shape[1],)))\n",
    "model.add(Dropout(0.3))  # 30% dropout\n",
    "\n",
    "# Hidden layer 1\n",
    "model.add(Dense(64, activation='relu'))\n",
    "model.add(Dropout(0.3))  # 30% dropout\n",
    "\n",
    "# Hidden layer 2\n",
    "model.add(Dense(32, activation='relu'))\n",
    "model.add(Dropout(0.3))  # 30% dropout\n",
    "\n",
    "# Hidden layer 3\n",
    "model.add(Dense(32, activation='relu'))\n",
    "model.add(Dropout(0.3))  # 30% dropout\n",
    "\n",
    "# Output layer\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "\n",
    "# Early stopping callback\n",
    "early_stopping = EarlyStopping(monitor='val_loss', patience=5)  # stops after 5 epochs of no improvement\n",
    "\n",
    "history = model.fit(\n",
    "    X_train_smote, y_train_smote, \n",
    "    epochs=50,  # increased number of epochs \n",
    "    batch_size=64,  # increased batch size for faster computation\n",
    "    validation_split=0.2,\n",
    "    callbacks=[early_stopping]  # using the early stopping callback\n",
    ")\n",
    "\n",
    "loss, accuracy = model.evaluate(X_test_scaled, y_test)\n",
    "print(f\"Test Accuracy: {accuracy * 100:.2f}%\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1bbfaf1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predicting the Test set results\n",
    "y_pred_proba = model.predict(X_test_scaled)\n",
    "y_pred_class = (y_pred_proba > 0.5).astype(\"int32\")  # Convert probabilities to class labels using 0.5 as a threshold\n",
    "\n",
    "# Generate classification report\n",
    "print(classification_report(y_test, y_pred_class))\n",
    "\n",
    "# Making the Confusion Matrix\n",
    "cm = confusion_matrix(y_test, y_pred_class)\n",
    "\n",
    "# Visualizing the Confusion Matrix\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', \n",
    "            xticklabels=['Negative (0)', 'Positive (1)'], \n",
    "            yticklabels=['Negative (0)', 'Positive (1)'])\n",
    "plt.xlabel('Predicted Labels')\n",
    "plt.ylabel('True Labels')\n",
    "plt.title('Confusion Matrix')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c40d5e1",
   "metadata": {},
   "source": [
    "## GuassianNB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad625225",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "\n",
    "# Initialize the Gaussian Naive Bayes model\n",
    "gnb = GaussianNB()\n",
    "\n",
    "# Fit the model to your training data\n",
    "gnb.fit(X_train_smote, y_train_smote)\n",
    "\n",
    "# Predict on your test data\n",
    "y_pred_gnb = gnb.predict(X_test_scaled)\n",
    "\n",
    "# Evaluate the performance\n",
    "print(\"Classification Report for Gaussian Naive Bayes:\\n\")\n",
    "print(classification_report(y_test, y_pred_gnb))\n",
    "\n",
    "print(\"\\nConfusion Matrix:\\n\")\n",
    "print(confusion_matrix(y_test, y_pred_gnb))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae3d9e2c",
   "metadata": {},
   "source": [
    "## Stacked model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87f0a40e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predictions from traditional models on the training set\n",
    "train_pred_logreg = logreg.predict_proba(X_train_smote)[:, 1]\n",
    "train_pred_knn = knn.predict_proba(X_train_smote)[:, 1]\n",
    "train_pred_svm = svm_model.decision_function(X_train_smote)\n",
    "train_pred_rf = rf.predict_proba(X_train_smote)[:, 1]\n",
    "\n",
    "# Predictions from the neural network on the training set\n",
    "train_pred_nn = model.predict(X_train_smote).ravel()\n",
    "\n",
    "# Stack all the predictions together\n",
    "stacked_train_predictions = np.column_stack((train_pred_logreg, train_pred_knn, train_pred_svm, train_pred_rf, train_pred_nn))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9737fb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "meta_model = LogisticRegression(max_iter=10000)\n",
    "meta_model.fit(stacked_train_predictions, y_train_smote)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff62ebc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predictions from traditional models on the test set\n",
    "test_pred_logreg = logreg.predict_proba(X_test_scaled)[:, 1]\n",
    "test_pred_knn = knn.predict_proba(X_test_scaled)[:, 1]\n",
    "test_pred_svm = svm_model.decision_function(X_test_scaled)\n",
    "test_pred_rf = rf.predict_proba(X_test_scaled)[:, 1]\n",
    "\n",
    "# Predictions from the neural network on the test set\n",
    "test_pred_nn = model.predict(X_test_scaled).ravel()\n",
    "\n",
    "# Stack all test predictions together\n",
    "stacked_test_predictions = np.column_stack((test_pred_logreg, test_pred_knn, test_pred_svm, test_pred_rf, test_pred_nn))\n",
    "\n",
    "# Final predictions from the meta-model\n",
    "final_predictions = meta_model.predict(stacked_test_predictions)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77f456ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Classification report for the meta_model\n",
    "print(\"Classification Report for Meta Model:\\n\")\n",
    "print(classification_report(y_test, final_predictions))\n",
    "\n",
    "# Confusion matrix for the meta_model\n",
    "conf_matrix = confusion_matrix(y_test, final_predictions)\n",
    "\n",
    "# Plotting the confusion matrix using seaborn\n",
    "plt.figure(figsize=(8,6))\n",
    "sns.heatmap(conf_matrix, annot=True, fmt='g', cmap='Blues')\n",
    "plt.xlabel('Predicted Labels')\n",
    "plt.ylabel('True Labels')\n",
    "plt.title('Confusion Matrix for Meta Model')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eae86281",
   "metadata": {},
   "source": [
    "## üë®‚Äçüíª ML MODEL FOR FIRST STREAMLIT VERSION\n",
    "\n",
    "Below I will try to make a dumb machine learning model with only gender, hip circumference and moderate work activity as predictors.\n",
    "\n",
    "Why? \n",
    "To make a basic Streamlit model that we can work more on when we have decided on the predictor values we will ask the user.\n",
    "- this includes taking a string input and converting it into one of the numbers our model us using\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f02ef3ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "#columns_for_dumb_model = [\"Doctor_Told_Diabetes\", \"Gender\", \"Hip Circumference (cm)\", \"Vigorous recreational activities\"]\n",
    "#df_3 = df_merged[columns_for_dumb_model]\n",
    "\n",
    "#df_3.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3afbd4f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#for column in df_3.columns:\n",
    "    #print(f\"Unique values in {column}:\")\n",
    "    #print(df_3[column].unique())\n",
    "    #print(\"-\" * 50)  # Just to separate the output for better visibility\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7212814",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the data into X (features) and y (target)\n",
    "#X = df_3.drop('Doctor_Told_Diabetes', axis=1)\n",
    "#y = df_3['Doctor_Told_Diabetes']\n",
    "\n",
    "# Split data into training and test sets\n",
    "#X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Scaling the data\n",
    "#scaler = StandardScaler()\n",
    "#X_train_scaled = scaler.fit_transform(X_train)\n",
    "#X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "# Initialize logistic regression model\n",
    "#logreg = LogisticRegression(max_iter=10000)\n",
    "\n",
    "# Fit the model to the training data\n",
    "#logreg.fit(X_train, y_train)\n",
    "\n",
    "# Predict on test data\n",
    "#y_pred = logreg.predict(X_test)\n",
    "\n",
    "# Evaluate the model\n",
    "#print(\"Accuracy:\", accuracy_score(y_test, y_pred))\n",
    "#print(classification_report(y_test, y_pred))\n",
    "\n",
    "#coefficients = logreg.coef_[0]\n",
    "#features = X.columns\n",
    "\n",
    "#coeff_df = pd.DataFrame({'Feature': features, 'Coefficient': coefficients})\n",
    "\n",
    "#sorted_coeff_df = coeff_df.sort_values(by='Coefficient', ascending=False)\n",
    "\n",
    "\n",
    "#print(sorted_coeff_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8b1ff99",
   "metadata": {},
   "outputs": [],
   "source": [
    "#X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed6bb02c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#X1 = np.array([[2., 172.8, 2.]])\n",
    "#X1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ea84376",
   "metadata": {},
   "outputs": [],
   "source": [
    "#y_pred = logreg.predict(X1)\n",
    "#y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d5ff4e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from joblib import dump\n",
    "\n",
    "# Save the logistic regression model and scaler\n",
    "#dump(logreg, 'logreg_model.joblib')\n",
    "#dump(scaler, 'scaler.joblib')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a82613d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
